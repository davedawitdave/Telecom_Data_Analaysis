{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d16fca39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandasql import sqldf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "class DataSummarizer:\n",
    "    \"\"\"\n",
    "    a class with list of data sumarizing methods.\n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    \n",
    "\n",
    "    def generateModel(self, x, y):\n",
    "        \"\"\"\n",
    "        a function that generates a regression model\n",
    "        \"\"\"\n",
    "        # Creating regression model and fitting it\n",
    "\n",
    "        # creating an object of LinearRegression class\n",
    "        model = LinearRegression()\n",
    "\n",
    "        # fitting the training data\n",
    "        model.fit(x,y)\n",
    "        print(\"Model created Sucessfully.\")\n",
    "        \n",
    "        return model\n",
    "\n",
    "\n",
    "    def clusterGenerator(self, df, selected_features, num_clusters, clust_name):\n",
    "        \"\"\"\n",
    "        a function that generates a K means cluster value to rows.\n",
    "        \"\"\"\n",
    "        selected_metrics = df[selected_features]\n",
    "\n",
    "        # Creating normalized dataframes\n",
    "\n",
    "        temp_arr = selected_metrics.loc[:, selected_features].values\n",
    "        temp_arr = StandardScaler().fit_transform(temp_arr) # normalizing the features\n",
    "\n",
    "        # Turning the temporary array of normalized values into a dataframe.\n",
    "\n",
    "        normal_df = pd.DataFrame(temp_arr,columns=selected_features)\n",
    "\n",
    "        # creating the clusters\n",
    "\n",
    "        kmeans = KMeans(num_clusters)\n",
    "        kmeans.fit(temp_arr)\n",
    "\n",
    "        # Generating cluster value to each row\n",
    "\n",
    "        identified_clusters = kmeans.fit_predict(temp_arr)\n",
    "        # Adding the generated array of cluster values to the dataframe as a column\n",
    "\n",
    "        data_with_clusters = df.copy()\n",
    "        data_with_clusters[clust_name] = identified_clusters \n",
    "        \n",
    "        return normal_df, data_with_clusters, kmeans\n",
    "\n",
    "    \n",
    "    def calcScore(self, df, cent, features, title):\n",
    "        df[title] = df.apply(lambda df : np.linalg.norm(df[features] - cent), axis = 1)\n",
    "        df2 = df[title]\n",
    "        df_norm = ((df2-df2.min())/(df2.max()-df2.min()))*100\n",
    "        df[title] = df_norm\n",
    "        return df \n",
    "\n",
    "\n",
    "    def show_N_per_col(self, df, main, cols, N, target=\"top\"):\n",
    "        \"\"\"\n",
    "        sorts a column and shows top 10 values.\n",
    "        \"\"\"\n",
    "        asc = False\n",
    "        if(target == \"bottom\"):\n",
    "            asc = True\n",
    "        for col in cols:\n",
    "            print(\"\\nTop 10 customers based on \"+col+\"\\n\")\n",
    "            print(df.sort_values(by=col, ascending=asc).loc[:,[main, col]].head(N))\n",
    "        \n",
    "    \n",
    "    def bivariateAnalysis(self, df, cols, colors): \n",
    "        \"\"\"\n",
    "        it plots a scatter chart and runs correlation test\n",
    "        \"\"\"\n",
    "        for i in range(len(cols)):\n",
    "            plt.style.use('fivethirtyeight')\n",
    "            plt.figure(figsize=(8, 4)) \n",
    "            sns.scatterplot(data = df, x=cols[i][0], y=cols[i][1], s=20, color=colors[i])\n",
    "            print(self.corrMatrix(df, cols[i]))\n",
    "\n",
    "\n",
    "    def showDistribution(self, df, cols, colors):\n",
    "        \"\"\"\n",
    "        Distribution plotting function.\n",
    "        \"\"\"\n",
    "        for index in range(len(cols)):\n",
    "            plt.style.use('fivethirtyeight')\n",
    "            plt.figure(figsize=(8, 4)) \n",
    "            sns.displot(data=df, x=cols[index], color=colors[index], kde=True, height=4, aspect=2)\n",
    "            plt.title(f'Distribution of '+cols[index]+' data volume', size=20, fontweight='bold')\n",
    "            plt.show()\n",
    "\n",
    "            \n",
    "    def plot_box(self, df:pd.DataFrame, col:str)->None:\n",
    "        \"\"\"\n",
    "        Boxplot plotting function.\n",
    "        \"\"\"\n",
    "        plt.boxplot(df[col])\n",
    "        plt.title(f'Plot of {col}', size=20, fontweight='bold')\n",
    "        ax = plt.gca()\n",
    "        #ax.set_ylim(top = df[col].quantile(0.9999))\n",
    "        #ax.set_ylim(bottom = 0)\n",
    "        # show plot\n",
    "        plt.show()\n",
    "\n",
    "    def plot_box2(self, df:pd.DataFrame, columns, color:str)->None:\n",
    "        \"\"\"\n",
    "        Boxplot plotting function.\n",
    "        \"\"\"\n",
    "        fig = plt.figure(figsize =(10, 7))\n",
    "        \n",
    "        for col in columns:\n",
    "            # Creating plot\n",
    "            plt.boxplot(df[col])\n",
    "            plt.title(f'Plot of {col}', size=20, fontweight='bold')\n",
    "            ax = plt.gca()\n",
    "            ax.set_ylim(top = df[col].quantile(0.9999))\n",
    "            ax.set_ylim(bottom = 0)\n",
    "            # show plot\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "    def plot_pie(self, df, col, title):\n",
    "        \"\"\"\n",
    "        pie chart plotting function.\n",
    "        \"\"\"\n",
    "        # Wedge properties\n",
    "        wp = { 'linewidth' : 1, 'edgecolor' : \"black\" }\n",
    "\n",
    "        # Creating autocpt arguments\n",
    "        def func(pct, allvalues):\n",
    "            absolute = int(pct / 100.*np.sum(allvalues))\n",
    "            return \"{:.1f}%\\n({:d} g)\".format(pct, absolute)\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize =(10, 7))\n",
    "        wedges, texts, autotexts = ax.pie(df[col[1]],\n",
    "                                    autopct = lambda pct: func(pct, df[col[1]]),\n",
    "                                    labels = df[col[0]].to_list(),\n",
    "                                    startangle = 90,\n",
    "                                    wedgeprops = wp,)\n",
    "\n",
    "        plt.setp(autotexts, size = 8, weight =\"bold\")\n",
    "        ax.set_title(title)\n",
    "\n",
    "\n",
    "    def percent_missing(self, df):\n",
    "        \"\"\"\n",
    "        this function calculates the total percentage of missin values in a dataset.\n",
    "        \"\"\"\n",
    "        # Calculate total number of cells in dataframe\n",
    "        totalCells = np.product(df.shape)\n",
    "\n",
    "        # Count number of missing values per column\n",
    "        missingCount = df.isnull().sum()\n",
    "\n",
    "        # Calculate total number of missing values\n",
    "        totalMissing = missingCount.sum()\n",
    "\n",
    "        # Calculate percentage of missing values\n",
    "        print(\"The dataset contains\", round(((totalMissing/totalCells) * 100), 2), \"%\", \"missing values.\")\n",
    "\n",
    "\n",
    "    def summ_columns(self, df, unique=True):\n",
    "        \"\"\"\n",
    "        shows columns and their missing values along with data types.\n",
    "        \"\"\"\n",
    "        df2 = df.isna().sum().to_frame().reset_index()\n",
    "        df2.rename(columns = {'index':'variables', 0:'missing_count'}, inplace = True)\n",
    "        df2['missing_percent_(%)'] = round(df2['missing_count']*100/df.shape[0])\n",
    "        data_type_lis = df.dtypes.to_frame().reset_index()\n",
    "        df2['data_type'] = data_type_lis.iloc[:,1]\n",
    "        \n",
    "        if(unique):\n",
    "            unique_val = []\n",
    "            for i in range(df2.shape[0]):\n",
    "                unique_val.append(len(pd.unique(df[df2.iloc[i,0]])))\n",
    "            df2['unique_values'] = pd.Series(unique_val)\n",
    "        return df2\n",
    "\n",
    "\n",
    "    def get_top_n(self, df, colname, num, globalDict):\n",
    "        \"\"\"\n",
    "        a function that groups a column and return the top n groups based on member count\n",
    "        \"\"\"\n",
    "        queryDf = lambda q: sqldf(q, globalDict)\n",
    "        query = 'SELECT \"'+colname+'\", count(*) as user_count FROM '+df+' WHERE \"'+colname+'\" != \"undefined\" group by \"'+colname+'\" order by user_count DESC LIMIT '+str(num)\n",
    "        return queryDf(query)\n",
    "\n",
    "\n",
    "    def manByHandset(self, lis, dfname, globalDict):\n",
    "        \"\"\"\n",
    "        a function that returns top three handsets from top three manufacturers\n",
    "        \"\"\"\n",
    "        queryDf = lambda q: sqldf(q, globalDict)\n",
    "        for man in lis:\n",
    "            query = 'SELECT \"Handset Manufacturer\", \"Handset Type\", count(*) as num_users \\\n",
    "            FROM '+dfname+'\\\n",
    "            WHERE \"Handset Manufacturer\" = \"'+man+'\" \\\n",
    "            group by \"Handset Type\" \\\n",
    "            order by num_users DESC \\\n",
    "            LIMIT 5'\n",
    "            print(queryDf(query),'\\n')\n",
    "\n",
    "\n",
    "    def find_agg(self, df, group_columns, agg_columns, agg_metrics, new_columns):\n",
    "        \"\"\"\n",
    "        a function that returns a new dataframe with aggregate values of specified columns.\n",
    "        \"\"\"\n",
    "        new_column_dict ={}\n",
    "        agg_dict = {}\n",
    "        for i in range(len(agg_columns)):\n",
    "            new_column_dict[agg_columns[i]] = new_columns[i]\n",
    "            agg_dict[agg_columns[i]] = agg_metrics[i]\n",
    "\n",
    "        new_df = df.groupby(group_columns).agg(agg_dict).reset_index().rename(columns=new_column_dict)\n",
    "        return new_df\n",
    "\n",
    "\n",
    "    def combineColumns(self, df, col1, col2, new_name, rem=False):\n",
    "        \"\"\"\n",
    "        combines two numerical variables and create new variable.\n",
    "        \"\"\"\n",
    "        df[new_name] = df[col1]+df[col2]\n",
    "        if(rem):\n",
    "            df.drop([col1, col2], axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "    def generateFreqTable(self, df, cols, range):\n",
    "        \"\"\"\n",
    "        generate a freqeuncy table\n",
    "        \"\"\"\n",
    "        for col in cols:\n",
    "            print(df[col].value_counts().iloc[:range,])\n",
    "\n",
    "\n",
    "    def summary_one(self, df, cols):\n",
    "        \"\"\"\n",
    "        calculate range, max, count, and min.\n",
    "        \"\"\"\n",
    "        df2 = df[cols]\n",
    "        data_types_dict = {'max': float, 'min':float}\n",
    "  \n",
    "        df_sum = df2.max().to_frame().reset_index().rename(columns={\"index\":\"variables\",0:\"max\"})\n",
    "        df_sum[\"min\"] = df2.min().to_frame().reset_index().iloc[:,1]\n",
    "        df_sum= df_sum.astype(data_types_dict)\n",
    "        df_sum['range'] = df_sum['max'] - df_sum['min']\n",
    "        df_sum[\"count\"] = df2.count().to_frame().reset_index().iloc[:,1]\n",
    "        return df_sum\n",
    "\n",
    "\n",
    "    def summary_two(self, df, cols):\n",
    "        \"\"\"\n",
    "        calculate central tendency measures.\n",
    "        \"\"\"\n",
    "        df2 = df[cols]\n",
    "        df_sum = df2.mean().to_frame().reset_index().rename(columns={\"index\":\"variables\",0:\"mean\"})\n",
    "        df_sum[\"median\"] = df2.median().to_frame().reset_index().iloc[:,1]\n",
    "        df_sum[\"mode\"] = df2.mode().iloc[:,1]\n",
    "        return df_sum\n",
    "\n",
    "\n",
    "    def summary_three(self, df, cols):\n",
    "        \"\"\"\n",
    "        calculate dispersion measures\n",
    "        \"\"\"\n",
    "        df2 = df[cols]\n",
    "        df_sum = df2.std().to_frame().reset_index().rename(columns={\"index\":\"variables\",0:\"std\"})\n",
    "        df_sum[\"var\"] = df2.var().to_frame().reset_index().iloc[:,1]\n",
    "        return df_sum\n",
    "\n",
    "\n",
    "    def bar_graph(self, df, cols, x_ax):\n",
    "        \"\"\"\n",
    "        graphical univariate analysis function. bar chart.\n",
    "        \"\"\"\n",
    "        plot_df = df[cols]\n",
    "        plt.figure(figsize=(25, 12))\n",
    "        sns.countplot(x= x_ax, data=plot_df)\n",
    "\n",
    "\n",
    "\n",
    "    def topDecile(self, df, group,deci, cols, metric, name, range):\n",
    "        \"\"\"\n",
    "        function that aggregates based on top n deciles.\n",
    "        \"\"\"\n",
    "        df['Decile'] = pd.qcut(df['session_dur'], 10, labels=False)\n",
    "        aggr_n = self.find_agg(df, group, cols, metric, name)\n",
    "        aggr_n = aggr_n.loc[aggr_n['Decile'] < range[1]+1]\n",
    "        aggr_n = aggr_n.loc[aggr_n['Decile'] > range[0]-1]\n",
    "        return aggr_n\n",
    "\n",
    "\n",
    "    def corrMatrix(self, df, cols):\n",
    "        \"\"\"\n",
    "        a function that generates correlation matrix as a table.\n",
    "        \"\"\"\n",
    "        relation = df[cols].corr()\n",
    "        return relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2359cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
